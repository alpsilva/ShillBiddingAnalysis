{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "\n",
    "import pandas\n",
    "\n",
    "# Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1337\n",
    "N_JOBS = -1\n",
    "FOLDS = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str, positive_label_multiplication: int = 2) -> pandas.DataFrame:\n",
    "    \"\"\" Receives a file path for the dataset training, testing and validation datasets. \"\"\"\n",
    "\n",
    "    # Loading data from csv file\n",
    "    df = pandas.read_csv(file_path)\n",
    "\n",
    "    # Selecting useful features\n",
    "    useful_features = [\n",
    "        \"Bidder_Tendency\",\n",
    "        \"Bidding_Ratio\",\n",
    "        \"Successive_Outbidding\",\n",
    "        \"Last_Bidding\",\n",
    "        \"Auction_Bids\",\n",
    "        \"Starting_Price_Average\",\n",
    "        \"Early_Bidding\",\n",
    "        \"Winning_Ratio\",\n",
    "        \"Auction_Duration\",\n",
    "        \"Class\"\n",
    "    ]\n",
    "\n",
    "    df = df[useful_features]\n",
    "\n",
    "    # Augmenting positive label data\n",
    "    positive_labels = df[df[\"Class\"] == 1]\n",
    "\n",
    "    dfs_to_concat = [df]\n",
    "    for _ in range(positive_label_multiplication):\n",
    "        dfs_to_concat.append(positive_labels)\n",
    "\n",
    "    df = pandas.concat(dfs_to_concat)\n",
    "    df = df.sample(frac=1)\n",
    "\n",
    "    # Separating features and labels\n",
    "    columns = list(df.columns)\n",
    "    features = columns[:len(columns)-1]\n",
    "    label = columns[len(columns)-1:]\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[label]\n",
    "\n",
    "    # Creating training, testing and validation datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = RANDOM_SEED)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.125, random_state = RANDOM_SEED)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./dataset/Shill Bidding Dataset.csv\"\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_valid, y_valid = load_data(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declarão de função para treinamento de modelos\n",
    "\n",
    "A ferramenta gridsearch será usada para determinar a melhor combinação de parâmetros para cada modelo.\n",
    "\n",
    "Uma função search é definida, que recebe uma instância de modelo a ser \"variado\" e um dicionário de parâmetros e suas variações. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(model, model_parameters, verbosity: int = 1): \n",
    "    \"\"\" \"\"\"\n",
    "    model_pipeline = Pipeline([\n",
    "        ('clf', model)\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model_pipeline,\n",
    "        model_parameters,\n",
    "        n_jobs=N_JOBS,\n",
    "        cv=FOLDS,\n",
    "        verbose=verbosity\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    print(f\"Best score after optimization: {grid_search.best_score_}\")\n",
    "    print(\"Best params:\")\n",
    "    for key, value in grid_search.best_params_.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando K-NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default para leaf_size é 30, então decidimos um range de 20 a 40\n",
    "p=0-> minkowski_distance,  p=1-> Manhattan distance, p=2-> Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_parameters = {\n",
    "    \"clf__n_neighbors\":range (4,10),\n",
    "    \"clf__weights\":[\"uniform\", \"distance\"],\n",
    "    \"clf__algorithm\":[\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"clf__leaf_size\":range(20,40),\n",
    "    \"clf__metric\":[\"cityblock\",\"cosine\",\"euclidean\",\"haversine\",\"nan_euclidean\"],\n",
    "    \"clf__p\":range(1,3)\n",
    "}\n",
    "\n",
    "gs_knn = search(KNeighborsClassifier(), knn_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando LVQ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max_depth começa com 3 porque é o minímo recomendado pelo Scikitlearn e vai até 50 porque raramente é necessário mais que 50. \n",
    "Min_samples_leaf foi recomendado ser entre 1 e 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parameters = {\n",
    "    \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"clf__splitter\": [\"best\", \"random\"],\n",
    "    \"clf__max_features\": [0.2,0.4,0.6,0.8, None, \"sqrt\", \"log2\"],\n",
    "    \"clf__max_depth\": range(3, 50),\n",
    "    \"clf__min_samples_split\": range(2, 10),\n",
    "    \"clf__min_samples_leaf\": range (1,20)\n",
    "\n",
    "}\n",
    "\n",
    "gs_dt = search(DecisionTreeClassifier(), dt_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como há muito mais exemplos da classe 0 que a classe 1, o peso dado aos exemplos da classe 1 foi maior para 1 melhor treinamento. \n",
    "O C foi entre 0.1 e 1.0 pois foram vistos exemplos de outros modelos sendo treinados e esses eram os valores vistos.\n",
    "O gamma é o coeficiente do kernel e o C o parâmetro de regularização. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_parameters = {\n",
    "    \"clf__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"clf__gamma\":[\"scale\", \"auto\"],\n",
    "    \"clf__C\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    \"clf__degree\":range (1,4), #degree of polinomial function\n",
    "    \"clf__class_weight\":[{0: 2, 1: 8}, \"balanced\"],\n",
    "    \"clf__decision_function_shape\":[\"ovr\",\"ovo\"] #one-vs-rest,one-vs-one\n",
    "}\n",
    "\n",
    "gs_svm = search(SVC(), svm_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando Random Forest\n",
    "Parâmetros e ranges escolhidos para a variação:\n",
    "1. n_estimators [50:150]: Número de árvores de decisão presentes na floresta.\n",
    "2. criterion [\"gini\", \"entropy\", \"log_loss\"]: Algoritmo para medição de qualidade de divisão de nós. Servem para determinar quais as melhores features para estarem mais perto do topo do árvore (ou seja, que apresentam maior ganho de informação).\n",
    "3. max_depth [3:50]: Profundida máxima da árvore. O próprio SKLearn recomenda 3 como mínimo. O máximo depende muito das situações, mas via de regra, uma árvore mais profunda representa um classificador com risco de overfitting. Manter uma profundidade balanceada pode garantir um modelo mais genérico que consegue lidar com registros novos (diferentes dos que foram usado para o treino) sem muitos problemas.\n",
    "4. max_features [\"sqrt\", \"log2\", None]: Número de atributos a serem considerados na hora de dividir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters = {\n",
    "    \"clf__n_estimators\": range(75, 125),\n",
    "    \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"clf__max_depth\": range(3, 20),\n",
    "    \"clf__max_features\": [0.2, 0.4, 0.6, 0.8, None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "gs_rf = search(RandomForestClassifier(random_state=RANDOM_SEED), rf_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando Rede Neural MLP\n",
    "Parâmetros e ranges escolhidos para a variação:\n",
    "1. hidden_layer_sizes [(100,), (50, 50,), (33, 33, 34,), (25, 25, 25, 25,)]: Quantidade de camadas internas do perceptron (e o número de neurons em cada uma)\n",
    "2. Activation [\"identity\", \"logistic\", \"tanh\", \"relu\"]: Função de ativação para os neurons. \n",
    "3. Solver [\"lbfgs\", \"sgd\"]: De acordo com o sklearn, o solver \"adam\" funciona melhor com datasets maiores (na casa das dezenas de milhares). Como nosso dataset tem uma escala menor, seu uso não é recomendado, pois as alternativas convergem mais rapidamente e performam melhor.\n",
    "4. Alpha: [0.0001, 0.0002, 0.0003, ..., 0.0009]: Termo de Regularização L2.\n",
    "5. Learning rate [\"constant\", \"invscaling\", \"adaptative\"]: Taxa de aprendizado que define as atualizações de peso.\n",
    "6. max_iter [50..1000]: Número de iterações a ocorrem internamente durante o treinamento. Maiores números significam mais tempo de processamento, e possivelmente mais precisão, já que o modelo terá mais tentativas para convergir numa solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_parameters = {\n",
    "    \"clf__hidden_layer_sizes\": [(100,), (50, 50,), (33, 33, 34,), (25, 25, 25, 25,)],\n",
    "    \"clf__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"clf__solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    # \"clf__alpha\": [x/10000 for x in range(1, 10)],\n",
    "    \"clf__learning_rate\": [\"constant\", \"invscaling\", \"adaptative\"],\n",
    "    # \"clf__max_iter\": range(50, 1000, 50)\n",
    "}\n",
    "\n",
    "gs_mlp = search(MLPClassifier(random_state=RANDOM_SEED), mlp_parameters, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando Comitê de redes neurais Artificiais\n",
    "Como o algoritmo Bagging é um ensemble e pode receber vários classificadores, decidimos instanciar o MLP com o resultado de sua otimização, para garantir maior qualidade do comitê.\n",
    "Parâmetros e ranges escolhidos para a variação:\n",
    "1. n_estimators [5:15]: Número de classificadores presentes no comitê.\n",
    "2. max_samples [0.2:1]: Número de registros a serem extraídos de X na hora de treinar cada classificador do comitê.\n",
    "3. max_features [0.2:1]: Número de atributos a serem considerados na hora de treinar cada classificador do comitê.\n",
    "4. bootstrap [True, False]: .\n",
    "5. bootstrap_features [True, False]: ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_mlp_parameters = {\n",
    "    \"clf__n_estimators\": range(5, 15),\n",
    "    \"clf__max_samples\": [0.2, 0.4, 0.6, 0.8, 1],\n",
    "    \"clf__max_features\": [0.2, 0.4, 0.6, 0.8, 1],\n",
    "    \"clf__bootstrap\": [True, False],\n",
    "    \"clf__bootstrap_features\": [True, False],\n",
    "}\n",
    "\n",
    "ideal_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(50, 50),\n",
    "    learning_rate=\"constant\",\n",
    "    activation=\"logistic\",\n",
    "    solver=\"lbfgs\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "gs_ensemble_mlp = search(BaggingClassifier(ideal_mlp, random_state=RANDOM_SEED), ensemble_mlp_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando Comitê Heterogêneo\n",
    "Como o algoritmo VotingClassifier é um ensemble e pode receber vários classificadores diferentes, decidimos instanciá-los já com os melhores parâmetros provenientes de suas otimizações. Os classificadores escolhidos para o VotingClassifier foram:\n",
    "- MLP\n",
    "- Decision Tree\n",
    "- SVM\n",
    "- KNN\n",
    "\n",
    "Parâmetros e ranges escolhidos para a variação:\n",
    "1. voting [\"hard\", \"soft\"]: Regra para definir vencedor da votação (maioria simples com hard, probabilidade de classes com soft).\n",
    "2. weights [None, [2.5, 2, 1.5, 1]]: pesos atribuídos para cada classificador. No caso de None, o peso é uniforme. Caso contrário, os pesos passados são atribuídos. Declaramos os classificadores em ordem do mais preciso para o menos preciso, garantindo que os melhores classificadores influenciem mais na decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_ensemble_parameters = {\n",
    "    \"clf__voting\": [\"hard\", \"soft\"],\n",
    "    \"clf__weights\": [None, [2.5, 2, 1.5, 1]]\n",
    "}\n",
    "\n",
    "estimators = [\n",
    "    (\"mlp\", MLPClassifier(\n",
    "        hidden_layer_sizes=(33, 33, 34,),\n",
    "        activation=\"tanh\",\n",
    "        solver=\"lbfgs\",\n",
    "        random_state=RANDOM_SEED\n",
    "    )),\n",
    "    (\"dt\", DecisionTreeClassifier(\n",
    "        criterion=\"gini\",\n",
    "        max_depth=38,\n",
    "        max_features=None,\n",
    "        splitter=\"random\",\n",
    "        random_state=RANDOM_SEED\n",
    "    )),\n",
    "    (\"svm\", SVC(\n",
    "        C= 1.0,\n",
    "        degree= 1,\n",
    "        gamma= \"auto\",\n",
    "        kernel= \"rbf\",\n",
    "        random_state=RANDOM_SEED\n",
    "    )),\n",
    "    (\"knn\", KNeighborsClassifier(\n",
    "        algorithm=\"auto\",\n",
    "        leaf_size=20,\n",
    "        n_neighbors=6,\n",
    "        p=2,\n",
    "        weights=\"distance\"\n",
    "    ))\n",
    "]\n",
    "\n",
    "voting_ensemble = search(VotingClassifier(estimators), voting_ensemble_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
